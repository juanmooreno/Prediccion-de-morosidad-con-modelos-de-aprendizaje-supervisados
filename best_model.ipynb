{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5a4cc7-a27f-47c5-95be-0883da466b2d",
   "metadata": {},
   "source": [
    "# Best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa66ff2-cf3a-4213-9e3d-7892aa220590",
   "metadata": {},
   "source": [
    "Redefinimos la funcion de preproceso, usada en cuadernos anteriores, quitando el randomundersampler para no perder ningún usuario por el camino. La función final será más escueta, pues solo necesitamos la última parte de esta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5020b897-e1aa-485b-8461-d21cffa95007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproceso(df, mas_comunes = None):\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    # Cargar etiquetas y unirlas al dataframe original\n",
    "    df_labels = pd.read_csv(\"train_labels.csv\")\n",
    "    df = pd.merge(df, df_labels, how=\"left\", on=\"ID\")\n",
    "\n",
    "    # Eliminar columnas con más del 90% de datos faltantes\n",
    "    pct_missing_columns = df.isnull().mean() * 100\n",
    "    cols_to_drop = pct_missing_columns[pct_missing_columns >= 90].index.to_list()\n",
    "    df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "    # Eliminar filas con más del 75% de datos faltantes\n",
    "    pct_missing_rows = df.isnull().mean(axis=1) * 100\n",
    "    rows_to_drop = pct_missing_rows[pct_missing_rows >= 75].index.to_list()\n",
    "    df.drop(rows_to_drop, axis=1, inplace=True)\n",
    "\n",
    "    # Imputar los valores faltantes con la moda de cada columna\n",
    "    df = df.apply(lambda col: col.fillna(col.mode()[0]))\n",
    "\n",
    "\n",
    "    # Procesar la columna de fechas\n",
    "    df[\"Expenditure_AHF\"] = pd.to_datetime(df[\"Expenditure_AHF\"])\n",
    "    df[\"year\"] = df[\"Expenditure_AHF\"].dt.year\n",
    "    df[\"month\"] = df[\"Expenditure_AHF\"].dt.month\n",
    "    df[\"day\"] = df[\"Expenditure_AHF\"].dt.day\n",
    "    df.drop(\"Expenditure_AHF\", axis=1, inplace=True)\n",
    "\n",
    "    # Convertir la columna 'ID' en una variable dummy y conservarla separada\n",
    "    ID = df.ID\n",
    "    df = pd.get_dummies(df.drop(\"ID\", axis=1))\n",
    "    df[\"ID\"] = ID\n",
    "\n",
    "    # Eliminar columnas con más del 80% de valores iguales a 1 o 0\n",
    "    only_ones = (df == 1).mean() * 100\n",
    "    only_ones = only_ones[only_ones >= 80].index.to_list()\n",
    "    only_zeros = (df == 0).mean() * 100\n",
    "    only_zeros = only_zeros[only_zeros >= 80].index.to_list()\n",
    "    borrar = only_ones + only_zeros\n",
    "    df.drop(borrar, axis=1, inplace=True)\n",
    "\n",
    "    # Normalizar las columnas numéricas\n",
    "    numerales = df.select_dtypes(include=\"number\").columns.to_list()\n",
    "    scaler = StandardScaler()\n",
    "    df[numerales] = scaler.fit_transform(df[numerales])\n",
    "\n",
    "    df = df[mas_comunes]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3db14bb5-dbf5-42a8-aaee-aec48da3c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(ruta_archivo, cols, tamaño_fragmento=100000):\n",
    "    import pandas as pd\n",
    "    dfs_list=[]\n",
    "    for i, fragmento in enumerate(pd.read_csv(ruta_archivo, chunksize=tamaño_fragmento)):\n",
    "        dfs_list.append(preproceso(fragmento, cols))\n",
    "        print(i)\n",
    "\n",
    "    dfs_final = pd.concat(dfs_list, ignore_index = True)\n",
    "    grouped_df = dfs_final.groupby(\"ID\").agg([\"mean\", \"std\"])\n",
    "    grouped_df.columns = [f\"{col}_{stat}\" for col, stat in grouped_df.columns]\n",
    "    grouped_df.fillna(0, inplace=True)\n",
    "    return grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3508b8-71a7-424e-8ab7-3db126e9a1b2",
   "metadata": {},
   "source": [
    "Traemos las columnas de forma directa desde processing y le aplicamos la función final para que los datos estén a la par con los que entrenaron el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a4b5a1-164b-495f-9306-5eef4bef784f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "cols = ['Payment_6804', 'Infraction_CGP', 'Base_7744', 'Base_80863', 'Risk_1930', 'Expenditure_JIG', 'Infraction_SNZ', 'Base_02683', 'Infraction_SBF',\n",
    "        'Infraction_ZWWJ', 'Infraction_QJJF', 'Base_76065', 'Infraction_EJZ', 'Base_6872', 'Risk_0322', 'Infraction_FMXQ', 'Infraction_GGO', 'ID']\n",
    "\n",
    "\n",
    "test_data = final(\"test_data.csv\", cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec6f1d2-4d96-4930-9d77-6f661e8b4e7b",
   "metadata": {},
   "source": [
    "Cargamos el mejor modelo entrenado en supervised (RandomForest) y predecimos los labels de test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c50c3efe-df90-4eec-ba10-dc84d6f10f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Cargamos el modelo desde el archivo\n",
    "with open('modelo_randomforest.pkl', 'rb') as file:\n",
    "    modelo_cargado = pickle.load(file)\n",
    "\n",
    "# Hacemos predicciones en el conjunto de prueba\n",
    "test_labels = modelo_cargado.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "678780e0-05a2-4fa4-92c6-94e7e59ebb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183566"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13bbfe-a3ff-4572-870b-51fa979d758e",
   "metadata": {},
   "source": [
    "Exportamos los datos para su evaluación, no sin antes ponerlos en un dataframe o serie para poder usar un método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeef67ad-da0c-4fb6-81e6-16b31c7b2439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_labels = pd.DataFrame(test_labels, columns = [\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59580cde-fa68-48ae-ac0d-d1b032d3d6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183561</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183562</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183563</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183564</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183565</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183566 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        labels\n",
       "0            1\n",
       "1            1\n",
       "2            0\n",
       "3            1\n",
       "4            0\n",
       "...        ...\n",
       "183561       0\n",
       "183562       0\n",
       "183563       0\n",
       "183564       0\n",
       "183565       1\n",
       "\n",
       "[183566 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97093d12-eb34-425a-af85-5ea4c5a9bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.to_csv(\"test_labels.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tu_entorno_3.10)",
   "language": "python",
   "name": "nombre_del_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
